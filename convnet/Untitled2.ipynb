{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN0AAADdCAIAAACwpuBNAAAApUlEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMCHAT1WAAHGWmR3AAAAAElFTkSuQmCC",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 221,
       "width": 221
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "# ... lunching using pid = 19832\t\n",
       "0\t\n",
       "1\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 221,
       "width": 221
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       "0,01 *\n",
       "  0,7349  0,9244  1,0807  0,9253  0,8961  0,8041  0,8894  1,1291  1,0949  1,0336\n",
       "  1,1303  1,6845  1,7372  1,4645  1,2467  1,1021  1,0790  1,1639  1,3783  1,4129\n",
       "  1,4442  1,9180  1,9498  1,2742  1,2700  1,2154  1,0250  0,9836  1,3235  1,4372\n",
       "  1,4397  1,8095  1,8795  1,2701  1,1191  1,0274  0,8794  0,8071  1,0149  1,0784\n",
       "  1,2991  1,6425  1,6618  1,4318  1,1276  0,9834  0,9962  0,9538  0,9348  1,0635\n",
       "  1,2069  1,4602  1,5644  1,3299  1,0826  0,9078  1,0513  1,0363  0,9798  1,0343\n",
       "  1,1117  1,3654  1,4655  1,1644  0,9825  1,0370  1,1019  1,0898  1,0617  1,0440\n",
       "  1,1671  1,3445  1,2986  1,0678  1,0144  1,0788  1,1244  1,1143  1,0884  1,0574\n",
       "  1,1601  1,3417  1,3338  1,1814  1,0729  1,1227  1,1385  1,1383  1,1103  1,0746\n",
       "  1,1974  1,4223  1,4062  1,2295  1,1503  1,1776  1,1545  1,1398  1,1348  1,0916\n",
       "  1,1860  1,4827  1,3535  1,2745  1,2197  1,1874  1,1517  1,1469  1,1461  1,1040\n",
       "  1,1517  1,5801  1,3573  1,2123  1,2525  1,2648  1,2017  1,1605  1,1475  1,1083\n",
       "  1,1222  1,6432  1,5063  1,2155  1,2110  1,2686  1,1474  1,1178  1,1178  1,1267\n",
       "  1,1785  1,5565  1,6193  1,0202  1,0780  1,1392  1,1385  1,1355  1,1169  1,1101\n",
       "  1,0818  0,9578  1,1288  1,0297  0,8680  0,8575  0,8849  0,9388  0,9463  0,9105\n",
       "\n",
       "Columns 11 to 15\n",
       "0,01 *\n",
       "  1,0124  0,8989  0,9934  1,1246  0,9379\n",
       "  1,5621  1,6945  1,7204  1,6885  1,3246\n",
       "  1,4841  1,5650  1,8626  2,0788  1,3250\n",
       "  1,1672  1,3432  1,6958  2,0646  1,3254\n",
       "  1,1222  1,1482  1,5738  1,8718  1,3185\n",
       "  1,0542  1,0817  1,4501  1,6237  1,2785\n",
       "  0,9939  0,9490  1,3563  1,5501  1,1924\n",
       "  1,0391  0,9355  1,2440  1,5843  1,2233\n",
       "  1,0929  0,9785  1,1981  1,5088  1,2613\n",
       "  1,0741  1,0526  1,1716  1,4393  1,2447\n",
       "  1,0694  1,0260  1,1778  1,4147  1,2198\n",
       "  1,0483  0,9900  1,1901  1,4460  1,2061\n",
       "  1,0578  1,0314  1,1830  1,4504  1,1433\n",
       "  1,0581  0,9257  1,1777  1,3796  1,0841\n",
       "  0,9218  0,8851  0,9712  1,2218  1,0948\n",
       "[torch.FloatTensor of size 15x15]\n",
       "\n",
       "Columns 1 to 10\n",
       "0,01 *\n",
       "  0,7349  0,9244  1,0807  0,9253  0,8961  0,8041  0,8894  1,1291  1,0949  1,0336\n",
       "  1,1303  1,6845  1,7372  1,4645  1,2467  1,1021  1,0790  1,1639  1,3783  1,4129\n",
       "  1,4442  1,9180  1,9498  1,2742  1,2700  1,2154  1,0250  0,9836  1,3235  1,4372\n",
       "  1,4397  1,8095  1,8795  1,2701  1,1191  1,0274  0,8794  0,8071  1,0149  1,0784\n",
       "  1,2991  1,6425  1,6618  1,4318  1,1276  0,9834  0,9962  0,9538  0,9348  1,0635\n",
       "  1,2069  1,4602  1,5644  1,3299  1,0826  0,9078  1,0513  1,0363  0,9798  1,0343\n",
       "  1,1117  1,3654  1,4655  1,1644  0,9825  1,0370  1,1019  1,0898  1,0617  1,0440\n",
       "  1,1671  1,3445  1,2986  1,0678  1,0144  1,0788  1,1244  1,1143  1,0884  1,0574\n",
       "  1,1601  1,3417  1,3338  1,1814  1,0729  1,1227  1,1385  1,1383  1,1103  1,0746\n",
       "  1,1974  1,4223  1,4062  1,2295  1,1503  1,1776  1,1545  1,1398  1,1348  1,0916\n",
       "  1,1860  1,4827  1,3535  1,2745  1,2197  1,1874  1,1517  1,1469  1,1461  1,1040\n",
       "  1,1517  1,5801  1,3573  1,2123  1,2525  1,2648  1,2017  1,1605  1,1475  1,1083\n",
       "  1,1222  1,6432  1,5063  1,2155  1,2110  1,2686  1,1474  1,1178  1,1178  1,1267\n",
       "  1,1785  1,5565  1,6193  1,0202  1,0780  1,1392  1,1385  1,1355  1,1169  1,1101\n",
       "  1,0818  0,9578  1,1288  1,0297  0,8680  0,8575  0,8849  0,9388  0,9463  0,9105\n",
       "\n",
       "Columns 11 to 15\n",
       "0,01 *\n",
       "  1,0124  0,8989  0,9934  1,1246  0,9379\n",
       "  1,5621  1,6945  1,7204  1,6885  1,3246\n",
       "  1,4841  1,5650  1,8626  2,0788  1,3250\n",
       "  1,1672  1,3432  1,6958  2,0646  1,3254\n",
       "  1,1222  1,1482  1,5738  1,8718  1,3185\n",
       "  1,0542  1,0817  1,4501  1,6237  1,2785\n",
       "  0,9939  0,9490  1,3563  1,5501  1,1924\n",
       "  1,0391  0,9355  1,2440  1,5843  1,2233\n",
       "  1,0929  0,9785  1,1981  1,5088  1,2613\n",
       "  1,0741  1,0526  1,1716  1,4393  1,2447\n",
       "  1,0694  1,0260  1,1778  1,4147  1,2198\n",
       "  1,0483  0,9900  1,1901  1,4460  1,2061\n",
       "  1,0578  1,0314  1,1830  1,4504  1,1433\n",
       "  1,0581  0,9257  1,1777  1,3796  1,0841\n",
       "  0,9218  0,8851  0,9712  1,2218  1,0948\n",
       "[torch.FloatTensor of size 15x15]\n",
       "\n",
       "0,007349050603807\t\n",
       "0,007349050603807\t\n",
       "0,007349050603807\t\n",
       "loss\t0\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "require 'src/Tools'\n",
    "require 'src/ArtistCriterion'\n",
    "require 'src/SpatialArtisticConvolution'\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "-- Command line arguments\n",
    "\n",
    "local cmd = torch.CmdLine()\n",
    "cmd:text()\n",
    "cmd:text('ArtisticNet')\n",
    "cmd:text()\n",
    "cmd:text('Options:')\n",
    "-- settings dataset building\n",
    "cmd:option('-seed', 1337, 'seed')\n",
    "cmd:option('-threads', 4, 'threads')\n",
    "\n",
    "cmd:text()\n",
    "opt = cmd:parse(arg or {})\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "-- Global Effects\n",
    "\n",
    "Tools.display_pid()\n",
    "\n",
    "torch.setdefaulttensortype('torch.FloatTensor')\n",
    "torch.manualSeed(opt.seed)\n",
    "torch.setnumthreads(opt.threads)\n",
    "\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "-- Model\n",
    "\n",
    "\n",
    "model = nn.Sequential()\n",
    "\n",
    "-- 18,916,480\n",
    "model:add(nn.SpatialArtisticConvolution(3, 96, 7, 7, 2, 2))\n",
    "model:add(nn.ReLU(true))\n",
    "model:add(nn.SpatialAveragePooling(3, 3, 3, 3))\n",
    "model:add(nn.SpatialArtisticConvolution(96, 256, 7, 7, 1, 1))\n",
    "model:add(nn.ReLU(true))\n",
    "model:add(nn.SpatialAveragePooling(2, 2, 2, 2))\n",
    "model:add(nn.SpatialArtisticConvolution(256, 512, 3, 3, 1, 1, 1, 1))\n",
    "model:add(nn.ReLU(true))\n",
    "model:add(nn.SpatialArtisticConvolution(512, 512, 3, 3, 1, 1, 1, 1))\n",
    "model:add(nn.ReLU(true))\n",
    "model:add(nn.SpatialArtisticConvolution(512, 1024, 3, 3, 1, 1, 1, 1))\n",
    "model:add(nn.ReLU(true))\n",
    "model:add(nn.SpatialArtisticConvolution(1024, 1024, 3, 3, 1, 1, 1, 1))\n",
    "model:add(nn.ReLU(true))\n",
    "-- classifier\n",
    "-- model:add(nn.SpatialAveragePooling(3, 3, 3, 3))\n",
    "-- model:add(lf.SpatialConvolution(opt, 1024, 4096, 5, 5, 1, 1))\n",
    "-- model:add(nn.ReLU(true))\n",
    "-- model:add(nn.Dropout(opt.dropout))\n",
    "-- model:add(lf.SpatialConvolution(opt, 4096, 4096, 1, 1, 1, 1))\n",
    "-- model:add(nn.ReLU(true))\n",
    "-- model:add(nn.Dropout(opt.dropout))\n",
    "-- model:add(lf.SpatialConvolution(opt, 4096, nb_class, 1, 1, 1, 1))\n",
    "-- model:add(nn.View(nb_class))\n",
    "-- model:add(nn.LogSoftMax())\n",
    "\n",
    "if opt.pretrain_model then\n",
    "    local m = model.modules\n",
    "    local ParamBank = require 'ParamBank'\n",
    "    local label = require 'overfeat_label'\n",
    "    local offset = 0\n",
    "    ParamBank:init(\"net_weight_1\")\n",
    "    ParamBank:read(        0, {96,3,7,7},      m[offset+1].weight)\n",
    "    ParamBank:read(    14112, {96},            m[offset+1].bias)\n",
    "    ParamBank:read(    14208, {256,96,7,7},    m[offset+4].weight)\n",
    "    ParamBank:read(  1218432, {256},           m[offset+4].bias)\n",
    "    ParamBank:read(  1218688, {512,256,3,3},   m[offset+7].weight)\n",
    "    ParamBank:read(  2398336, {512},           m[offset+7].bias)\n",
    "    ParamBank:read(  2398848, {512,512,3,3},   m[offset+9].weight)\n",
    "    ParamBank:read(  4758144, {512},           m[offset+9].bias)\n",
    "    ParamBank:read(  4758656, {1024,512,3,3},  m[offset+11].weight)\n",
    "    ParamBank:read(  9477248, {1024},          m[offset+11].bias)\n",
    "    ParamBank:read(  9478272, {1024,1024,3,3}, m[offset+13].weight)\n",
    "    ParamBank:read( 18915456, {1024},          m[offset+13].bias)\n",
    "    -- ParamBank:read( 18916480, {4096,1024,5,5}, m[offset+16].weight)\n",
    "    -- ParamBank:read(123774080, {4096},          m[offset+16].bias)\n",
    "    -- ParamBank:read(123778176, {4096,4096,1,1}, m[offset+18].weight)\n",
    "    -- ParamBank:read(140555392, {4096},          m[offset+18].bias)\n",
    "    -- ParamBank:read(140559488, {1000,4096,1,1}, m[offset+20].weight)\n",
    "    -- ParamBank:read(144655488, {1000},          m[offset+20].bias)\n",
    "end\n",
    "\n",
    "prepare = function (path2img, dim_in, dim_out)\n",
    "    local dim     = dim_in or 221\n",
    "    local dim_out = dim_out or 221\n",
    "    local img_dim\n",
    "    local img_raw = image.load(path2img) -- [0,1] -> [0,255]img\n",
    "    local rh = img_raw:size(2)\n",
    "    local rw = img_raw:size(3)\n",
    "\n",
    "    -- rescale to 3 * 256 * 256\n",
    "    if rh < rw then\n",
    "       rw = math.floor(rw / rh * dim)\n",
    "       rh = dim\n",
    "    else\n",
    "       rh = math.floor(rh / rw * dim)\n",
    "       rw = dim\n",
    "    end\n",
    "    local img_scale = image.scale(img_raw, rw, rh)\n",
    "    local offsetx = 1\n",
    "    local offsety = 1\n",
    "    if rh < rw then\n",
    "        offsetx = offsetx + math.floor((rw-dim)/2)\n",
    "    else\n",
    "        offsety = offsety + math.floor((rh-dim)/2)\n",
    "    end\n",
    "    img = img_scale[{{},{offsety,offsety+dim-1},{offsetx,offsetx+dim-1}}]:floor()\n",
    "\n",
    "    if crop_type then\n",
    "        local w1, h1\n",
    "        if crop_type == 1 then -- center\n",
    "            w1 = math.ceil((dim - dim_out) / 2)\n",
    "            h1 = math.ceil((dim - dim_out) / 2)\n",
    "        elseif crop_type == 2 then -- top-left\n",
    "            w1 = 1\n",
    "            h1 = 1\n",
    "        elseif crop_type == 3 then -- top-right\n",
    "            w1 = dim - dim_out\n",
    "            h1 = 1\n",
    "        elseif crop_type == 4 then -- bottom-left\n",
    "            w1 = 1\n",
    "            h1 = dim - dim_out\n",
    "        elseif crop_type == 5 then -- bottom-right\n",
    "            w1 = dim - dim_out\n",
    "            h1 = dim - dim_out\n",
    "        else\n",
    "            error('crop_type error')\n",
    "        end\n",
    "        img = image.crop(img, w1, h1, w1 + dim_out, h1 + dim_out)\n",
    "    end\n",
    "    \n",
    "    if flip then\n",
    "        img = image.hflip(img)\n",
    "    end\n",
    "\n",
    "    -- add mean and div std\n",
    "    if mean and std then \n",
    "        img:add(mean)\n",
    "        img:cdiv(std)\n",
    "    end\n",
    "\n",
    "    return img\n",
    "end\n",
    "\n",
    "layer = {1, 4, 7, 9, 11, 13}\n",
    "l = layer[6]\n",
    "\n",
    "criterion = nn.ArtistCriterion()\n",
    "\n",
    "input_origin = prepare('bee.jpg')\n",
    "input_gener  = prepare('fraise.jpg')\n",
    "\n",
    "print(input_origin[{1,1,1}])\n",
    "print(input_gener[{1,1,1}])\n",
    "\n",
    "itorch.image(input_origin)\n",
    "itorch.image(input_gener)\n",
    "\n",
    "activ_origin = model:forward(input_origin)\n",
    "activ_gener  = model:forward(input_gener)\n",
    "\n",
    "print(activ_origin[1])\n",
    "print(activ_gener[1])\n",
    "\n",
    "loss = criterion:forward(activ_origin, activ_gener)\n",
    "print('loss', loss)\n",
    "\n",
    "df_di = criterion:backward(activ_origin, activ_gener)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   3\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   3\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 3]\n",
       "\n",
       "\n",
       "   6\n",
       " 510\n",
       " 510\n",
       "[torch.LongStorage of size 3]\n",
       "\n",
       "\n",
       "   3\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 3]\n",
       "\n",
       "\n",
       "   6\n",
       " 510\n",
       " 510\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   6\n",
       " 510\n",
       " 510\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
